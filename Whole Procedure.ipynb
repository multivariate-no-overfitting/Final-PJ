{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature enigneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target we remove: 3,452\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.drop('id',axis = 1,inplace = True)\n",
    "test.drop('id',axis = 1,inplace = True)\n",
    "\n",
    "print('Number of target we remove: {:,}'.format(sum(train.cancel == -1)))\n",
    "train = train[train.cancel != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[~train['zip.code'].isnull()]\n",
    "test['zip.code'].fillna(train['zip.code'].mode()[0],inplace = True)\n",
    "\n",
    "train_copy = train.copy()\n",
    "test_copy = test.copy()\n",
    "train_copy.drop('cancel',axis = 1,inplace = True)\n",
    "train_copy['train'] = 1\n",
    "test_copy['train'] = 0\n",
    "all_data = pd.concat([train_copy,test_copy],axis = 0).reset_index(drop = True)\n",
    "\n",
    "target = train.cancel.reset_index(drop = True)\n",
    "all_data_train = all_data[all_data.train == 1].drop('train',axis = 1)\n",
    "all_data_test = all_data[all_data.train == 0].drop('train',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_threshold = 100\n",
    "all_data.loc[all_data['ni.age'] > Age_threshold,'ni.age'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length at residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of residence null rate:0.57%\n"
     ]
    }
   ],
   "source": [
    "all_data.loc[all_data['len.at.res'] > all_data['ni.age'],'len.at.res'] = np.nan\n",
    "\n",
    "print('Length of residence null rate:{:.2%}'.format(all_data['len.at.res'].isnull().sum()/len(all_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenure null rate:0.10%\n"
     ]
    }
   ],
   "source": [
    "all_data.loc[all_data['tenure'] > all_data['ni.age'],'tenure'] = np.nan\n",
    "\n",
    "print('Tenure null rate:{:.2%}'.format(all_data['tenure'].isnull().sum()/len(all_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipcode & income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#zipcode = pd.read_csv('zip_code.csv',sep = ';')\n",
    "#income = pd.read_csv('US_Income.csv',encoding = 'ISO-8859-1')\n",
    "\n",
    "#all_data = all_data.merge(zipcode,left_on = 'zip.code',right_on = 'Zip',how = 'left')\n",
    "\n",
    "zip_income = pd.read_excel(\"MedianZIP-3.xlsx\")\n",
    "zip_income.head()\n",
    "all_data = all_data.merge(zip_income,left_on = 'zip.code',right_on = 'Zip',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.drop(['Zip'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['dwelling.type'] = np.where(all_data['dwelling.type'] == 'House','House','Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_train = all_data[all_data['train'] == 1].drop('train',axis = 1)\n",
    "all_data_test = all_data[all_data['train'] == 0].drop('train',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NA with mode & median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_na_numerical(col):\n",
    "    return all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "numerical_cols = ['ni.age','len.at.res','premium','n.adults','n.children','tenure','Median','Mean','Pop']\n",
    "categorical_cols = ['zip.code','house.color','credit','coverage.type','dwelling.type','sales.channel',\n",
    "                   'ni.gender','ni.marital.status','claim.ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_train[numerical_cols] = all_data_train[numerical_cols].fillna(all_data_train[numerical_cols].median())\n",
    "\n",
    "all_data_test[numerical_cols] = all_data_test[numerical_cols].fillna(all_data_train[numerical_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_train['family_size'] = all_data_train['n.adults'] + all_data_train['n.children']\n",
    "all_data_test['family_size'] = all_data_test['n.adults'] + all_data_test['n.children']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_encoding(col,smooth = 1):\n",
    "    all_data_train['target'] = target\n",
    "    prior = target.mean()\n",
    "    n = all_data_train.groupby(col).size()\n",
    "\n",
    "    means = all_data_train.groupby(col).target.mean() \n",
    "    smooth_mean = (n*means + smooth*prior)/(n + smooth)\n",
    "    \n",
    "    all_data_train[col + '_encoding'] = all_data_train[col].map(smooth_mean)\n",
    "    all_data_test[col + '_encoding'] = all_data_test[col].map(smooth_mean)\n",
    "\n",
    "    all_data_train[col + '_encoding'].fillna(prior,inplace = True)\n",
    "    all_data_test[col + '_encoding'].fillna(prior,inplace = True)\n",
    "\n",
    "    all_data_train.drop(['target',col],axis = 1,inplace = True)\n",
    "    all_data_test.drop(col,axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    mean_encoding(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ni.age</th>\n",
       "      <th>len.at.res</th>\n",
       "      <th>premium</th>\n",
       "      <th>n.adults</th>\n",
       "      <th>n.children</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Pop</th>\n",
       "      <th>...</th>\n",
       "      <th>coverage.type_encoding</th>\n",
       "      <th>dwelling.type_encoding</th>\n",
       "      <th>sales.channel_encoding</th>\n",
       "      <th>ni.gender_encoding</th>\n",
       "      <th>ni.marital.status_encoding</th>\n",
       "      <th>claim.ind_encoding</th>\n",
       "      <th>pmed_ratio</th>\n",
       "      <th>pmean_ratio</th>\n",
       "      <th>p_perad</th>\n",
       "      <th>p_perp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>950.507336</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99669.2313</td>\n",
       "      <td>144247.8556</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251935</td>\n",
       "      <td>0.258435</td>\n",
       "      <td>0.181762</td>\n",
       "      <td>0.241706</td>\n",
       "      <td>0.257989</td>\n",
       "      <td>0.228874</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>475.253668</td>\n",
       "      <td>475.253668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>909.346046</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31956.2752</td>\n",
       "      <td>38214.0329</td>\n",
       "      <td>38872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231298</td>\n",
       "      <td>0.258435</td>\n",
       "      <td>0.181762</td>\n",
       "      <td>0.241706</td>\n",
       "      <td>0.235740</td>\n",
       "      <td>0.228874</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>181.869209</td>\n",
       "      <td>181.869209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>897.084502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70750.2531</td>\n",
       "      <td>79724.2953</td>\n",
       "      <td>30051.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231298</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>0.329669</td>\n",
       "      <td>0.242612</td>\n",
       "      <td>0.257989</td>\n",
       "      <td>0.228874</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>897.084502</td>\n",
       "      <td>897.084502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.366136</td>\n",
       "      <td>979.039007</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53746.2317</td>\n",
       "      <td>64582.2710</td>\n",
       "      <td>15329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231298</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>0.329669</td>\n",
       "      <td>0.242612</td>\n",
       "      <td>0.257989</td>\n",
       "      <td>0.295541</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>195.807801</td>\n",
       "      <td>195.807801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>932.379027</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67760.3587</td>\n",
       "      <td>74438.4069</td>\n",
       "      <td>680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251935</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>0.181762</td>\n",
       "      <td>0.242612</td>\n",
       "      <td>0.235740</td>\n",
       "      <td>0.228874</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>466.189513</td>\n",
       "      <td>155.396504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  ni.age  len.at.res     premium  n.adults  n.children  tenure  \\\n",
       "0  2013    37.0   18.000000  950.507336       2.0         0.0    15.0   \n",
       "1  2013    40.0   17.000000  909.346046       5.0         0.0    15.0   \n",
       "2  2013    45.0   14.000000  897.084502       1.0         0.0    14.0   \n",
       "3  2013    45.0   24.366136  979.039007       5.0         0.0    22.0   \n",
       "4  2013    36.0   16.000000  932.379027       2.0         4.0     4.0   \n",
       "\n",
       "       Median         Mean      Pop     ...      coverage.type_encoding  \\\n",
       "0  99669.2313  144247.8556  27946.0     ...                    0.251935   \n",
       "1  31956.2752   38214.0329  38872.0     ...                    0.231298   \n",
       "2  70750.2531   79724.2953  30051.0     ...                    0.231298   \n",
       "3  53746.2317   64582.2710  15329.0     ...                    0.231298   \n",
       "4  67760.3587   74438.4069    680.0     ...                    0.251935   \n",
       "\n",
       "   dwelling.type_encoding  sales.channel_encoding  ni.gender_encoding  \\\n",
       "0                0.258435                0.181762            0.241706   \n",
       "1                0.258435                0.181762            0.241706   \n",
       "2                0.229433                0.329669            0.242612   \n",
       "3                0.229433                0.329669            0.242612   \n",
       "4                0.229433                0.181762            0.242612   \n",
       "\n",
       "   ni.marital.status_encoding  claim.ind_encoding  pmed_ratio  pmean_ratio  \\\n",
       "0                    0.257989            0.228874    0.004768     0.003295   \n",
       "1                    0.235740            0.228874    0.005691     0.004759   \n",
       "2                    0.257989            0.228874    0.012680     0.011252   \n",
       "3                    0.257989            0.295541    0.003643     0.003032   \n",
       "4                    0.235740            0.228874    0.006880     0.006263   \n",
       "\n",
       "      p_perad      p_perp  \n",
       "0  475.253668  475.253668  \n",
       "1  181.869209  181.869209  \n",
       "2  897.084502  897.084502  \n",
       "3  195.807801  195.807801  \n",
       "4  466.189513  155.396504  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_feature(dt):\n",
    "    dt['pmed_ratio'] = dt['premium']/dt['Median']/dt['n.adults']\n",
    "    dt['pmean_ratio'] = dt['premium']/dt['Mean']/dt['n.adults']\n",
    "    dt['p_perad'] = dt['premium']/dt['n.adults']\n",
    "    dt['p_perp'] = dt['premium']/dt['family_size']\n",
    "\n",
    "add_feature(all_data_train)\n",
    "add_feature(all_data_test)\n",
    "all_data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = all_data_train\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Random Search\n",
    "def skf_cv(X, y,clf,folds = 3):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "    X_arr,y_arr = np.array(X),np.array(y)\n",
    "    skf = StratifiedKFold(n_splits=folds,random_state = 123)\n",
    "    cv_train = []\n",
    "    cv_test = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        x_tr,x_val = X_arr[train_index],X_arr[val_index]\n",
    "        y_tr,y_val = y_arr[train_index],y_arr[val_index]\n",
    "        clf.fit(x_tr,y_tr)\n",
    "        predict_test = clf.predict_proba(x_val)[:,1]\n",
    "        predict_train = clf.predict_proba(x_tr)[:,1]\n",
    "        cv_test.append(roc_auc_score(y_val,predict_test))\n",
    "        cv_train.append(roc_auc_score(y_tr,predict_train))\n",
    "    return np.mean(cv_train),np.mean(cv_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(base_score=0.5, \n",
    "                    booster='gbtree',\n",
    "                    colsample_bylevel=1,\n",
    "                    colsample_bytree=.8, \n",
    "                    gamma=0.1,\n",
    "                    eta=0.02, \n",
    "                    max_delta_step=0,\n",
    "                    max_depth=6,\n",
    "                    min_child_weight=1, \n",
    "                    min_samples_leaf=5,\n",
    "                    min_samples_split=5, \n",
    "                    missing=None, \n",
    "                    n_estimators=100\n",
    "                    , n_jobs=3, \n",
    "                    objective='binary:logistic', \n",
    "                    random_state=123,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.8, \n",
    "                    scale_pos_weight=1,\n",
    "                    silent=True, \n",
    "                    subsample=0.8)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "auc_train = roc_auc_score(y_train,xgb.predict_proba(X_train)[:,1])\n",
    "auc_test = roc_auc_score(y_test,xgb.predict_proba(X_test)[:,1])\n",
    "print('train AUC: {train:.2%}, test AUC {test:.2%}'.format(train = auc_train,test = auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(xgb.feature_importances_,X_train.columns)), columns=['Value','Feature'])\n",
    "select_ft = feature_imp.sort_values(by=\"Value\", ascending=False)[\"Feature\"][0:15]\n",
    "X_train_select =X_train[select_ft]\n",
    "X_test_select =X_test[select_ft]\n",
    "xgb.fit(X_train_select,y_train)\n",
    "auc_train = roc_auc_score(y_train,xgb.predict_proba(X_train_select)[:,1])\n",
    "auc_test = roc_auc_score(y_test,xgb.predict_proba(X_test_select)[:,1])\n",
    "print('train AUC: {train:.2%}, test AUC {test:.2%}'.format(train = auc_train,test = auc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced_subsample',\n",
    "                            n_estimators = 2000,\n",
    "                            max_depth = 10,\n",
    "                            min_samples_leaf = 15,\n",
    "                            min_samples_split = 5,\n",
    "                            max_features = 'sqrt',\n",
    "                            random_state = 123,\n",
    "                            n_jobs = 24)\n",
    "\n",
    "rf.fit(X_train_select,y_train)\n",
    "\n",
    "auc_train = roc_auc_score(y_train,rf.predict_proba(X_train)[:,1])\n",
    "auc_test = roc_auc_score(y_test,rf.predict_proba(X_test)[:,1])\n",
    "print('train AUC: {train:.2%}, test AUC {test:.2%}'.format(train = auc_train,test = auc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_estimator = lgb.LGBMClassifier(num_leaves = 2**9,\n",
    "                                  min_data_in_leaf = 1000,\n",
    "                                   n_estimators = 2000,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   subsample_for_bin=200000,\n",
    "                                  max_depth = 9,\n",
    "                                  learning_rate = 0.02,\n",
    "                                  bagging_freq = 6,\n",
    "                                  bagging_fraction = 0.7,\n",
    "                                  reg_lambda = 0.8,\n",
    "                                  random_seed = 123,\n",
    "                                  metric = 'auc',\n",
    "                                  objective = 'binary',\n",
    "                                   boosting_type = 'dart',\n",
    "                                  verbosity = -1,\n",
    "                                  num_threads = 24)\n",
    "\n",
    "lgb_estimator.fit(X_train,y_train)\n",
    "\n",
    "auc_train = roc_auc_score(y_train,lgb_estimator.predict_proba(X_train)[:,1])\n",
    "auc_test = roc_auc_score(y_test,lgb_estimator.predict_proba(X_test)[:,1])\n",
    "\n",
    "print('train AUC: {train:.2%}, test AUC {test:.2%}'.format(train = auc_train,test = auc_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(learning_rate = .1,\n",
    "                             n_estimators  =200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adaboost.fit(X_train,y_train)\n",
    "auc_train = roc_auc_score(y_train,adaboost.predict_proba(X_train)[:,1])\n",
    "auc_test = roc_auc_score(y_test,adaboost.predict_proba(X_test)[:,1])\n",
    "print('train AUC: {train:.2%}, test AUC {test:.2%}'.format(train = auc_train,test = auc_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "    kf = StratifiedKFold(n_splits = NFOLDS, random_state=123)\n",
    "    \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train,y_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)[:,1]\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_oof_train,rf_oof_test = get_oof(rf, X.values, y.values, all_data_test.values)\n",
    "print('rf finish')\n",
    "lgb_oof_train,lgb_oof_test = get_oof(lgb_estimator, X.values, y.values, all_data_test.values)\n",
    "print('lgb finish')\n",
    "xgb_oof_train, xgb_oof_test = get_oof(xgb, X.values, y.values, all_data_test.values)\n",
    "print('xgb finish')\n",
    "ada_oof_train, ada_oof_test = get_oof(adaboost, X.values, y.values, all_data_test.values)\n",
    "print('ada finish')\n",
    "nb_oof_train, nb_oof_test = get_oof(nb, X.values, y.values, all_data_test.values)\n",
    "print('all finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_stack = np.concatenate((rf_oof_train,lgb_oof_train,xgb_oof_train,nb_oof_train), axis=1)\n",
    "x_test_stack = np.concatenate((rf_oof_test,lgb_oof_test,xgb_oof_test,nb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=123,\n",
    "                        solver='saga',\n",
    "                        max_iter = 200,\n",
    "                        class_weight='balanced',\n",
    "                       C = 1)\n",
    "\n",
    "LR.fit(x_train_stack, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf_cv(x_train_stack, y,LR,folds = 5)\n",
    "result = LR.predict_proba(x_test_stack)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(pd.read_csv('test.csv')['id'])\n",
    "temp['Predicted'] = result\n",
    "temp.columns = ['ID','Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
